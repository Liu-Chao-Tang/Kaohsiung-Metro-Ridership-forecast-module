import streamlit as st
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from forecast_core import ForecastModel
from io import BytesIO

matplotlib.rcParams['font.family'] = 'Microsoft JhengHei'
matplotlib.rcParams['axes.unicode_minus'] = False

st.set_page_config(page_title="é«˜é›„æ·é‹-é‹é‡é æ¸¬ç³»çµ± ver. 1", layout="wide")
st.markdown("<h1 style='text-align: center;'>é«˜é›„æ·é‹-é‹é‡é æ¸¬ç³»çµ± ver. 1</h1>", unsafe_allow_html=True)

@st.cache_data
def cached_load():
    df = pd.read_excel("data/daily_volume.xlsx", index_col=0, parse_dates=True)
    return df

df = cached_load()

all_numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
volume_cols = [col for col in all_numeric_columns if 'é‹é‡' in col]

default_target = 'ç¸½é‹é‡' if 'ç¸½é‹é‡' in volume_cols else volume_cols[0]

st.header("1. é æ¸¬é …ç›®é¸æ“‡")
target_col = st.selectbox(
    "é æ¸¬é …ç›®ï¼ˆåƒ…é™é‹é‡ç›¸é—œæ¬„ä½ï¼‰ï¼š",
    volume_cols,
    index=volume_cols.index(default_target) if default_target in volume_cols else 0)
exog_options = [col for col in df.columns if col != target_col]

last_actual_date = df[target_col].replace(0, np.nan).dropna().index.max()
min_date = df.index.min()
max_date = last_actual_date if pd.notnull(last_actual_date) else df.index.max()

st.header("2. é æ¸¬æ¨¡å‹é¸æ“‡")
mode = st.radio("", ("å°ˆå®¶æ¨¡å¼ï¼ˆè‡ªå‹•é¸æ“‡æœ€å„ªæ¨¡å‹é‹ç®—ï¼‰", "è‡ªè¨‚æ¨¡å¼"))

if mode == "å°ˆå®¶æ¨¡å¼ï¼ˆè‡ªå‹•é¸æ“‡æœ€å„ªæ¨¡å‹é‹ç®—ï¼‰":
    m = 7
    search_speed = st.radio("æ¨¡å‹æœå°‹æ¨¡å¼", ["å¿«é€Ÿï¼ˆé‹ç®—æ™‚é–“çŸ­ï¼‰", "ç²¾æº–ï¼ˆæº–ç¢ºç‡è¼ƒé«˜ï¼‰"])
    stepwise_mode = True if search_speed == "å¿«é€Ÿï¼ˆé‹ç®—æ™‚é–“çŸ­ï¼‰" else False
else:
    st.subheader("è‡ªè¨‚æ¨¡å¼ï¼šè«‹é¸æ“‡æ¨¡å‹é¡å‹")
    model_type = st.selectbox("é¸æ“‡æ¨¡å‹ï¼š", ["AR", "MA", "ARIMA", "SARIMAX"], index=3, format_func=lambda x: {
        "AR": "AR (è‡ªè¿´æ­¸æ¨¡å‹)",
        "MA": "MA (ç§»å‹•å¹³å‡æ¨¡å‹)",
        "ARIMA": "ARIMA (æ•´åˆç§»å‹•å¹³å‡è‡ªè¿´æ­¸æ¨¡å‹)",
        "SARIMAX": "SARIMAX (å­£ç¯€æ€§æ•´åˆç§»å‹•å¹³å‡è‡ªè¿´æ­¸æ¨¡å‹)"
    }[x])

    if model_type == "AR":
        p = st.number_input("AR p", min_value=1, value=1, step=1)
        d = q = P = D = Q = S = 0
    elif model_type == "MA":
        q = st.number_input("MA q", min_value=1, value=1, step=1)
        p = d = P = D = Q = S = 0
    elif model_type == "ARIMA":
        p = st.number_input("AR p", min_value=0, value=1, step=1)
        d = st.number_input("å·®åˆ† d", min_value=0, value=1, step=1)
        q = st.number_input("MA q", min_value=0, value=1, step=1)
        P = D = Q = S = 0
    else:
        p = st.number_input("AR p", min_value=0, value=1, step=1)
        d = st.number_input("å·®åˆ† d", min_value=0, value=1, step=1)
        q = st.number_input("MA q", min_value=0, value=1, step=1)
        P = st.number_input("å­£ç¯€æ€§ AR P", min_value=0, value=1, step=1)
        D = st.number_input("å­£ç¯€æ€§å·®åˆ† D", min_value=0, value=1, step=1)
        Q = st.number_input("å­£ç¯€æ€§ MA Q", min_value=0, value=1, step=1)
        S = st.number_input("å­£ç¯€æ€§é€±æœŸ S (å¤©)", min_value=1, value=7, step=1)
        m = S

st.header("3. å½±éŸ¿å› å­é¸æ“‡(å¤–ç”Ÿè®Šæ•¸)")
use_exog = st.radio("", ("å¦(åƒ…ä»¥æ­·å²é‹é‡è³‡æ–™é€²è¡Œé æ¸¬)", "æ˜¯(è€ƒé‡å…¶ä»–å½±éŸ¿å› ç´ )")) == "æ˜¯(è€ƒé‡å…¶ä»–å½±éŸ¿å› ç´ )"
selected_exog = []
if use_exog:
    st.markdown("è«‹å‹¾é¸è¦ä½¿ç”¨çš„å¤–ç”Ÿè®Šæ•¸ï¼š")
    for i, exog in enumerate(exog_options, start=1):
        label = f"è®Šæ•¸{i}-{exog}"
        default_checked = any(k in exog for k in ["æº«åº¦", "é™é›¨", "å‡æ—¥"])
        if st.checkbox(label, key=exog, value=default_checked):
            selected_exog.append(exog)

st.header("4. ç¾æœ‰é‹é‡è³‡æ–™ç¯„åœ")
st.markdown(f"è³‡æ–™æ—¥æœŸç¯„åœï¼š**{min_date.date()}** è‡³ **{max_date.date()}**")

with st.form("forecast_form"):
    st.header("5. æ¨¡å¼è¨“ç·´èˆ‡é æ¸¬æœŸé–“è¨­å®š")
    train_start = st.date_input("è¨“ç·´é–‹å§‹æ—¥", min_value=min_date.date(), max_value=max_date.date(), value=min_date.date())
    train_end = st.date_input("è¨“ç·´çµæŸæ—¥", min_value=min_date.date(), max_value=max_date.date(), value=max_date.date())
    n_forecast_days = st.slider("é æ¸¬å¤©æ•¸", min_value=1, max_value=365, value=7)
    submitted = st.form_submit_button("åŸ·è¡Œé æ¸¬")

if submitted:
    try:
        st.info("é–‹å§‹åŸ·è¡Œé æ¸¬...")
    
        import time
        start_time = time.time()

        train_start_dt = pd.to_datetime(train_start)
        train_end_dt = pd.to_datetime(train_end)
        forecast_start_dt = train_end_dt + pd.Timedelta(days=1)
        forecast_end_dt = forecast_start_dt + pd.Timedelta(days=n_forecast_days - 1)

        if train_start_dt > train_end_dt:
            st.error("è¨“ç·´é–‹å§‹æ—¥æœŸä¸å¯æ™šæ–¼çµæŸæ—¥æœŸ")
            st.stop()

        progress = st.progress(0, text="å»ºç«‹æ¨¡å‹ä¸­...")

        fm = ForecastModel(df, target_col, use_exog, selected_exog)

        if mode == "å°ˆå®¶æ¨¡å¼ï¼ˆè‡ªå‹•é¸æ“‡æœ€å„ªæ¨¡å‹é‹ç®—ï¼‰":
            import time
            t0 = time.time()
            order, seasonal_order = fm.auto_fit(train_start_dt, train_end_dt, m=m, expert_mode=True, stepwise_mode=stepwise_mode)
            t1 = time.time()
            st.write(f"auto_fit() è€—æ™‚: {t1 - t0:.2f} ç§’")
            model_type = "SARIMAX"
            st.success(f"è‡ªå‹•æ¨¡å‹åƒæ•¸ï¼šorder={order}, seasonal_order={seasonal_order}")
        else:
            order = (p, d, q)
            seasonal_order = (P, D, Q, S)

        t1 = time.time()
        elapsed1 = t1 - start_time
        est_total = elapsed1 / 0.3
        remaining = est_total - elapsed1
        progress.progress(30, text=f"è¨“ç·´æ¨¡å‹ä¸­... â³ é ä¼°å‰©é¤˜ {remaining:.1f} ç§’")

        try:
            model_result = fm.fit(train_start_dt, train_end_dt, order, seasonal_order, model_type)
        except Exception as e:
            st.error("âŒ æ¨¡å‹è¨“ç·´å¤±æ•—ï¼Œè«‹æª¢æŸ¥åƒæ•¸æˆ–è³‡æ–™æ ¼å¼")
            st.stop()

        t2 = time.time()
        elapsed2 = t2 - start_time
        est_total = elapsed2 / 0.6
        remaining = est_total - elapsed2
        progress.progress(60, text=f"é æ¸¬ä¸­... â³ é ä¼°å‰©é¤˜ {remaining:.1f} ç§’")

        df_forecast = fm.forecast(forecast_start_dt, forecast_end_dt)
        
        progress.progress(100, text="âœ… é æ¸¬å®Œæˆ")
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        st.success(f"â±ï¸ é æ¸¬æµç¨‹å…±èŠ±è²»æ™‚é–“ï¼š{elapsed_time:.2f} ç§’")

        actuals = df[target_col].reindex(df_forecast.index)
        df_result = df_forecast.copy()
        df_result['å¯¦éš›å€¼'] = actuals
        df_result['é æ¸¬èª¤å·®(%)'] = np.where(
            (df_result['å¯¦éš›å€¼'].isna()) | (df_result['å¯¦éš›å€¼'] == 0),
            np.nan,
            (abs(df_result['å¯¦éš›å€¼'] - df_result['é æ¸¬å€¼']) / df_result['å¯¦éš›å€¼']) * 100
        ).round(2)

        df_result = df_result[['å¯¦éš›å€¼', 'é æ¸¬å€¼', 'ä¸‹é™', 'ä¸Šé™', 'é æ¸¬èª¤å·®(%)']]
        mean_error = df_result['é æ¸¬èª¤å·®(%)'].mean()

        st.subheader("é æ¸¬çµæœ")

        def color_error(val):
            if pd.isna(val):
                return ''
            return 'color: red' if val >= 10 else ''

        styled_df = df_result.style.format({
            'å¯¦éš›å€¼': '{:,.0f}',
            'é æ¸¬å€¼': '{:,.0f}',
            'ä¸‹é™': '{:,.0f}',
            'ä¸Šé™': '{:,.0f}',
            'é æ¸¬èª¤å·®(%)': '{:.2f}%'
        }).applymap(lambda v: 'color: green; font-weight: bold;' if pd.notna(v) else '', subset=['å¯¦éš›å€¼']) \
          .applymap(color_error, subset=['é æ¸¬èª¤å·®(%)'])

        st.dataframe(styled_df, use_container_width=True)
        st.markdown(f"<h4>ğŸ“Š å¹³å‡é æ¸¬èª¤å·®(%)ï¼š{mean_error:.2f}%</h4>", unsafe_allow_html=True)

        if mean_error >= 10:
            st.warning("âš ï¸ é æ¸¬èª¤å·®åé«˜ï¼Œå»ºè­°æª¢æŸ¥è³‡æ–™æˆ–èª¿æ•´æ¨¡å‹")

        towrite = BytesIO()
        df_result.to_excel(towrite, index=True)
        st.divider()
        st.download_button("ğŸ“¥ ä¸‹è¼‰é æ¸¬çµæœ Excel", towrite.getvalue(), file_name="forecast_result.xlsx")

        df_eval = df_result.dropna(subset=['å¯¦éš›å€¼'])
        if not df_eval.empty:
            st.divider()
            with st.expander("é¡¯ç¤ºæ¨¡å‹ç¸¾æ•ˆæŒ‡æ¨™ç¸½è¡¨"):
                metrics = fm.calculate_metrics(df_eval['å¯¦éš›å€¼'], df_eval['é æ¸¬å€¼'])

                metrics_info = {
                    'MAPE (%)': {
                        'æ¨™æº–': '<=10%',
                        'èªªæ˜': 'å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·®ï¼Œè¡¡é‡é æ¸¬èª¤å·®ç›¸å°æ–¼å¯¦éš›å€¼çš„ç™¾åˆ†æ¯”ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v <= 10 else ('æ™®é€š' if v <= 20 else 'å·®')
                    },
                    'R-squared': {
                        'æ¨™æº–': '>=0.8',
                        'èªªæ˜': 'æ¨¡å‹è§£é‡‹è®Šç•°çš„æ¯”ä¾‹ï¼Œè¶Šé«˜ä»£è¡¨æ¨¡å‹è¶Šå¥½ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v >= 0.8 else ('æ™®é€š' if v >= 0.6 else 'å·®')
                    },
                    'Adjusted R-squared': {
                        'æ¨™æº–': '>=0.8',
                        'èªªæ˜': 'èª¿æ•´åƒæ•¸æ•¸é‡å¾Œçš„Rå¹³æ–¹ï¼Œé¿å…éåº¦æ“¬åˆã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v >= 0.8 else ('æ™®é€š' if v >= 0.6 else 'å·®')
                    },
                    'Stabilized R-squared': {
                        'æ¨™æº–': '>=0.8',
                        'èªªæ˜': 'åœ¨å·®åˆ†å¾Œè³‡æ–™ä¸Šçš„æ¨¡å‹è§£é‡‹èƒ½åŠ›ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v >= 0.8 else ('æ™®é€š' if v >= 0.6 else 'å·®')
                    },
                    'RMSE': {
                        'æ¨™æº–': 'è¶Šä½è¶Šå¥½',
                        'èªªæ˜': 'å‡æ–¹æ ¹èª¤å·®ï¼Œåæ˜ é æ¸¬èª¤å·®å¤§å°ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v < 10000 else ('æ™®é€š' if v < 20000 else 'å·®')
                    },
                    'MAE': {
                        'æ¨™æº–': 'è¶Šä½è¶Šå¥½',
                        'èªªæ˜': 'å¹³å‡èª¤å·®å€¼ï¼Œè¶Šä½è¶Šå¥½ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v < 10000 else ('æ™®é€š' if v < 20000 else 'å·®')
                    },
                    'Max AE': {
                        'æ¨™æº–': 'è¶Šä½è¶Šå¥½',
                        'èªªæ˜': 'æœ€å¤§èª¤å·®å€¼ï¼Œåå·®æœ€å¤§æƒ…æ³ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v < 20000 else ('æ™®é€š' if v < 40000 else 'å·®')
                    },
                    'Normalized BIC': {
                        'æ¨™æº–': 'è¶Šä½è¶Šå¥½',
                        'èªªæ˜': 'æ¯ç­†æ¨£æœ¬çš„BICæŒ‡æ¨™ï¼Œè¶Šä½è¶Šå¥½ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v < 50 else ('æ™®é€š' if v < 100 else 'å·®')
                    },
                    'AIC': {
                        'æ¨™æº–': 'è¶Šä½è¶Šå¥½',
                        'èªªæ˜': 'è¡¡é‡æ¨¡å‹é©é…åº¦èˆ‡ç°¡å–®æ€§çš„è³‡è¨Šé‡æº–å‰‡ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v < 10000 else ('æ™®é€š' if v < 20000 else 'å·®')
                    },
                    'Ljung-Box p-value': {
                        'æ¨™æº–': '>0.05ç‚ºä½³',
                        'èªªæ˜': 'æª¢é©—æ®˜å·®æ˜¯å¦ç‚ºç™½å™ªéŸ³ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v > 0.05 else 'å·®'
                    },
                    'Durbin-Watson': {
                        'æ¨™æº–': 'ç´„ 2 ç‚ºä½³',
                        'èªªæ˜': 'Durbin-Watson çµ±è¨ˆé‡ç”¨æ–¼æª¢é©—æ®˜å·®è‡ªç›¸é—œï¼Œç´„ç­‰æ–¼2è¡¨ç¤ºç„¡è‡ªç›¸é—œã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if 1.5 <= v <= 2.5 else 'å·®'
                    },
                    'æ¨£æœ¬æ•¸ N': {
                        'æ¨™æº–': 'è¶Šå¤§è¶Šç©©å®š',
                        'èªªæ˜': 'è©•ä¼°æ¨£æœ¬æ•¸ï¼Œç”¨æ–¼è¡¡é‡è¨“ç·´è³‡æ–™é‡ã€‚',
                        'åˆ¤æ–·': lambda v: 'å¥½' if v >= 30 else ('æ™®é€š' if v >= 10 else 'å·®')
                    }
                }

                rows = []
                priority_order = ['MAPE (%)', 'R-squared', 'Adjusted R-squared', 'Stabilized R-squared',
                                  'RMSE', 'MAE', 'Max AE', 'Normalized BIC', 'AIC', 'Ljung-Box p-value', 'Durbin-Watson', 'æ¨£æœ¬æ•¸ N']

                for key in priority_order:
                    val = metrics.get(key, np.nan)
                    std = metrics_info[key]['æ¨™æº–']
                    desc = metrics_info[key]['èªªæ˜']

                    if isinstance(val, (int, float, np.float64, np.float32)) and not np.isnan(val):
                        judge = metrics_info[key]['åˆ¤æ–·'](val)
                        val_str = f"{val:.4f}" if "p-value" in key or "%" in key else f"{val:.2f}"
                    else:
                        judge = '-'
                        val_str = str(val)

                    rows.append([key, val_str, std, judge, desc])

                df_metrics = pd.DataFrame(rows, columns=['æŒ‡æ¨™', 'æ¨¡å‹å¯¦éš›å€¼', 'åˆ¤æ–·æ¨™æº–', 'åˆ¤åˆ¥çµæœ', 'æŒ‡æ¨™èªªæ˜'])

                st.dataframe(
                    df_metrics.style.applymap(
                        lambda v: 'color: red' if v == 'å·®' else ('color: orange' if v == 'æ™®é€š' else 'color: green'),
                        subset=['åˆ¤åˆ¥çµæœ']
                    ),
                    use_container_width=True
                )

                summary_text = fm.summarize_quality(metrics)
                if "âŒ" in summary_text:
                    st.error(summary_text)
                else:
                    st.success(summary_text)

        # ----- åªåœ¨å±•é–‹å€å¡Šå…§é¡¯ç¤ºé æ¸¬åœ– -----
        with st.expander("ğŸ“ˆ é¡¯ç¤ºé‹é‡é æ¸¬åœ–è¡¨"):
            fig, ax1 = plt.subplots(figsize=(12, 6))
            ax2 = ax1.twinx()
            ax1.plot(df_result.index, df_result['å¯¦éš›å€¼'], label='å¯¦éš›å€¼', color='blue', marker='o')
            ax1.plot(df_result.index, df_result['é æ¸¬å€¼'], label='é æ¸¬å€¼', color='orange', marker='s')
            ax1.fill_between(df_result.index, df_result['ä¸‹é™'], df_result['ä¸Šé™'], color='gray', alpha=0.2)

            ax2.bar(df_result.index, df_result['é æ¸¬èª¤å·®(%)'], alpha=0.3, color='red', label='é æ¸¬èª¤å·®(%)')
            ax2.set_ylim(0, 150)
            ax2.set_ylabel("é æ¸¬èª¤å·®(%)")

            ax1.set_ylabel(target_col)
            ax1.grid(True)
            ax1.legend(loc='upper left')
            ax2.legend(loc='upper right')
            ax1.set_title("å¯¦éš›å€¼ã€é æ¸¬å€¼åŠé æ¸¬èª¤å·®(%)è¶¨å‹¢")

            for x, y in zip(df_result.index, df_result['å¯¦éš›å€¼']):
                if pd.notna(y):
                    ax1.text(x, y, f"{int(y):,}", fontsize=8, color='blue', ha='left', va='bottom')
            for x, y in zip(df_result.index, df_result['é æ¸¬å€¼']):
                if pd.notna(y):
                    ax1.text(x, y, f"{int(y):,}", fontsize=8, color='orange', ha='right', va='bottom')
            for x, y in zip(df_result.index, df_result['é æ¸¬èª¤å·®(%)']):
                if pd.notna(y):
                    ax2.text(x, y, f"{y:.1f}%", fontsize=7, color='red', ha='center', va='bottom')

            st.pyplot(fig)

        # ----- åˆä½µ ACF/PACF åŸå§‹èˆ‡æ®˜å·®åœ– -----
        from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

        with st.expander("ğŸ“Š é¡¯ç¤º ACF / PACF åˆ†æåœ–ï¼ˆåŸå§‹è³‡æ–™èˆ‡æ®˜å·®ï¼‰"):
            orig_series = df[target_col].loc[train_start_dt:train_end_dt].dropna()
            resid_series = None
            if hasattr(model_result, "resid"):
                resid_series = model_result.resid.dropna()

            fig_acf_pacf, axes = plt.subplots(2, 2, figsize=(14, 8))

            # åŸå§‹è³‡æ–™ ACF
            plot_acf(orig_series, ax=axes[0,0], lags=40)
            axes[0,0].set_title("åŸå§‹è³‡æ–™ ACF")

            # åŸå§‹è³‡æ–™ PACF
            plot_pacf(orig_series, ax=axes[0,1], lags=40, method='ywm')
            axes[0,1].set_title("åŸå§‹è³‡æ–™ PACF")

            # æ®˜å·® ACF
            if resid_series is not None and len(resid_series) > 0:
                plot_acf(resid_series, ax=axes[1,0], lags=40)
                axes[1,0].set_title("æ®˜å·® ACF")
            else:
                axes[1,0].axis('off')

            # æ®˜å·® PACF
            if resid_series is not None and len(resid_series) > 0:
                plot_pacf(resid_series, ax=axes[1,1], lags=40, method='ywm')
                axes[1,1].set_title("æ®˜å·® PACF")
            else:
                axes[1,1].axis('off')

            plt.tight_layout()
            st.pyplot(fig_acf_pacf)
        if not df_eval.empty:
            with st.expander("ğŸ“Š æ¨¡å‹çµ±è¨ˆæ‘˜è¦"):
                st.code(str(model_result.summary()), language='text')

        with st.expander("ğŸ“˜ é™„éŒ„-æ¨¡å‹åè©è§£é‡‹ï¼ˆè‹±æ–‡ / ä¸­æ–‡ / å®šç¾©èªªæ˜ï¼‰"):
            glossary_df = pd.DataFrame([
                ["AR,Autoregressive", "è‡ªè¿´æ­¸æ¨¡å‹", "Autoregressive Model: åˆ©ç”¨è‡ªèº«éå»çš„æ•¸æ“šå€¼ä¾†é æ¸¬æœªä¾†å€¼ã€‚"],
                ["MA,Moving Average", "ç§»å‹•å¹³å‡æ¨¡å‹", "Moving Average Model: åˆ©ç”¨éå»èª¤å·®é …çš„ç·šæ€§çµ„åˆä¾†é æ¸¬ã€‚"],
                ["ARIMA,Autoregressive Integrated Moving Average", "æ•´åˆç§»å‹•å¹³å‡è‡ªè¿´æ­¸æ¨¡å‹", "Autoregressive Integrated Moving Average Model: åŒ…å«å·®åˆ†è™•ç†ä»¥è®“è³‡æ–™å¹³ç©©ã€‚"],
                ["SARIMAX,Seasonal ARIMA with Exogenous Variables", "å­£ç¯€æ€§ARIMAå¤–ç”Ÿè®Šæ•¸æ¨¡å‹", "åœ¨ARIMAåŸºç¤ä¸ŠåŠ ä¸Šå­£ç¯€æ€§æˆåˆ†èˆ‡å¤–ç”Ÿè®Šæ•¸ã€‚"],
                ["MAPE", "å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·®", "è¡¡é‡é æ¸¬å€¼èˆ‡å¯¦éš›å€¼ä¹‹é–“çš„å¹³å‡ç™¾åˆ†æ¯”èª¤å·®ã€‚"],
                ["R-squared", "æ±ºå®šä¿‚æ•¸", "è¡¡é‡æ¨¡å‹è§£é‡‹è®Šç•°ç¨‹åº¦çš„æŒ‡æ¨™ï¼Œä»‹æ–¼0åˆ°1ä¹‹é–“ã€‚"],
                ["RMSE", "å‡æ–¹æ ¹èª¤å·®", "èª¤å·®å¹³æ–¹çš„å¹³å‡å¾Œå†é–‹æ ¹è™Ÿï¼Œè¡¨ç¤ºå¹³å‡é æ¸¬èª¤å·®ã€‚"]
            ], columns=["è‹±æ–‡ç¸®å¯«", "ä¸­æ–‡åç¨±", "å®šç¾©èªªæ˜"])

            st.dataframe(glossary_df, use_container_width=True)

    except Exception as e:
        st.error(f"åŸ·è¡Œé æ¸¬ç™¼ç”ŸéŒ¯èª¤: {e}")
